from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import pandas as pd
import re
import os
from datetime import datetime
from dateutil.relativedelta import relativedelta
from urllib.parse import urlparse

# ===== CONFIG =====
MONTH_TO_SCRAPE = 5   # üëà ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
MAX_HOUSES = 0        # üëà ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á (0 = ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)

# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ URL ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ scrape (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏ß‡πá‡∏ö) ‚Äî ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô fallback
URLS = [
     "https://www.devillegroups.com/allcalendar/?s=1758",  # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 1: Deville Groups
    "https://poolvillacity.co.th/CITY-743",               # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 2: Pool Villa City
     "https://www.pattayapartypoolvilla.com/v/2246",       # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 3: Pattaya Party Pool Villa
]
# ==================


def load_urls_from_webpath():
    """‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ URL ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå webpath ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î: ‡∏ä‡∏∑‡πà‡∏≠\tURL ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ä‡∏∑‡πà‡∏≠ URL (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á)
    ‡∏Ç‡πâ‡∏≤‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå (# ...)
    """
    here = os.path.dirname(os.path.abspath(__file__))
    webpath = os.path.join(here, "webpath")

    urls = []
    if not os.path.exists(webpath):
        return urls

    with open(webpath, "r", encoding="utf-8") as f:
        for raw in f:
            line = raw.strip()
            if not line or line.startswith("#"):
                continue
            # ‡∏´‡∏≤ URL ‡∏î‡πâ‡∏ß‡∏¢ regex (http:// ‡∏´‡∏£‡∏∑‡∏≠ https://)
            url_match = re.search(r'https?://[^\s]+', line)
            if url_match:
                urls.append(url_match.group(0))
    return urls


class CalendarScraper:
    """Base class ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö scraping ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô"""
    
    # Map ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ -> ‡πÄ‡∏•‡∏Ç‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
    THAI_MONTH_MAP = {
        '‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°': 1, '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå': 2, '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°': 3, '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô': 4,
        '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°': 5, '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô': 6, '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°': 7, '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°': 8,
        '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô': 9, '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°': 10, '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô': 11, '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°': 12
    }
    
    def __init__(self, driver):
        self.driver = driver
        self.results = []
        self.today = datetime.now().date()  # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
    
    def filter_past_dates(self, results):
        """
        ‡∏Å‡∏£‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡∏±‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏≠‡∏≠‡∏Å (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå)
        
        ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏∑‡∏≠‡∏ô:
        - "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏° 2569" (‡∏û.‡∏®.)
        - "2026-01" (‡∏Ñ.‡∏®.)
        """
        filtered = []
        
        for row in results:
            try:
                month_str = row.get('‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '')
                day = int(row.get('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', 0))
                
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô year, month
                year, month = self._parse_month_string(month_str)
                
                if year and month and day:
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á date object
                    from datetime import date
                    row_date = date(year, month, day)
                    
                    # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà >= ‡∏ß‡∏±‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                    if row_date >= self.today:
                        filtered.append(row)
            except Exception as e:
                # ‡∏ñ‡πâ‡∏≤ parse ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô
                filtered.append(row)
        
        return filtered
    
    def _parse_month_string(self, month_str):
        """
        ‡πÅ‡∏õ‡∏•‡∏á string ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô (year, month)
        
        ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö:
        - "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏° 2569" -> (2026, 1)
        - "2026-01" -> (2026, 1)
        """
        try:
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏° 2569"
            for thai_month, month_num in self.THAI_MONTH_MAP.items():
                if thai_month in month_str:
                    # ‡∏´‡∏≤‡∏õ‡∏µ ‡∏û.‡∏®.
                    year_match = re.search(r'(25\d{2}|26\d{2}|27\d{2})', month_str)
                    if year_match:
                        thai_year = int(year_match.group(1))
                        # ‡πÅ‡∏õ‡∏•‡∏á ‡∏û.‡∏®. ‡πÄ‡∏õ‡πá‡∏ô ‡∏Ñ.‡∏®.
                        year = thai_year - 543
                        return (year, month_num)
            
            # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö "2026-01"
            match = re.match(r'(\d{4})-(\d{2})', month_str)
            if match:
                year = int(match.group(1))
                month = int(match.group(2))
                return (year, month)
                
        except:
            pass
        
        return (None, None)
    
    def detect_site_type(self, url):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏à‡∏≤‡∏Å URL"""
        domain = urlparse(url).netloc.lower()
        
        if 'devillegroups.com' in domain:
            return 'deville'
        elif 'poolvillacity.co.th' in domain:
            return 'poolvillacity'
        elif 'pattayapartypoolvilla.com' in domain:
            return 'pattayaparty'
        else:
            return 'unknown'
    
    def scrape(self, url):
        """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å scraper ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå"""
        site_type = self.detect_site_type(url)
        
        print(f"\n{'='*60}")
        print(f"üåê URL: {url}")
        print(f"üìå ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {site_type}")
        print(f"{'='*60}")
        
        if site_type == 'deville':
            return self.scrape_deville(url)
        elif site_type == 'poolvillacity':
            return self.scrape_poolvillacity(url)
        elif site_type == 'pattayaparty':
            return self.scrape_pattayaparty(url)
        else:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå: {url}")
            return []


    # ========================================================
    # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 1: Deville Groups (‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡πâ‡∏≤‡∏ô‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß + iframe)
    # ========================================================
    def scrape_deville(self, url):
        """Scrape ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡∏à‡∏≤‡∏Å devillegroups.com"""
        print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å Deville Groups...")
        
        BASE_IFRAME_URL = "https://www.devillegroups.com/allcalendar/cld.php"
        
        self.driver.get(url)
        time.sleep(8)
        
        results = []
        html = self.driver.page_source
        
        # ‡∏´‡∏≤ pattern: <h6>(DV-xxxx)<br>‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡πâ‡∏≤‡∏ô</h6>...<iframe src="cld.php?hId=xxxx"
        pattern = r'<h6>\(DV-(\d+)\)<br>([^<]+)</h6>.*?src="cld\.php\?hId=(\d+)"'
        matches = re.findall(pattern, html, re.DOTALL)
        
        houses = []
        seen_ids = set()
        
        for dv_id, name, h_id in matches:
            if h_id in seen_ids:
                continue
            seen_ids.add(h_id)
            
            house_name = name.strip()
            houses.append({
                'id': h_id,
                'name': house_name,
                'dv_code': f'DV-{dv_id}'
            })
            print(f"  üè† ‡∏û‡∏ö‡∏ö‡πâ‡∏≤‡∏ô: {house_name} (DV-{dv_id}, hId={h_id})")
        
        print(f"\nüìä ‡∏û‡∏ö‡∏ö‡πâ‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(houses)} ‡∏´‡∏•‡∏±‡∏á")
        
        if not houses:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡πâ‡∏≤‡∏ô")
            return results
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡πâ‡∏≤‡∏ô
        if MAX_HOUSES > 0:
            houses = houses[:MAX_HOUSES]
            print(f"üîß ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡∏∂‡∏á‡πÅ‡∏Ñ‡πà {MAX_HOUSES} ‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏£‡∏Å")
        
        # ‡∏ß‡∏ô‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡πâ‡∏≤‡∏ô
        start_date = datetime.now()
        total_houses = len(houses)
        
        for house_idx, house in enumerate(houses, 1):
            h_id = house['id']
            house_name = house['name']
            dv_code = house['dv_code']
            
            print(f"\n{'='*50}")
            print(f"üè† [{house_idx}/{total_houses}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á: {house_name} ({dv_code})")
            print(f"{'='*50}")
            
            for i in range(MONTH_TO_SCRAPE):
                try:
                    target_date = start_date + relativedelta(months=i)
                    ym = target_date.strftime("%Y-%m")
                    calendar_url = f"{BASE_IFRAME_URL}?ym={ym}&hId={h_id}"
                    
                    self.driver.get(calendar_url)
                    time.sleep(2)
                    
                    wait = WebDriverWait(self.driver, 10)
                    
                    # ‡∏≠‡πà‡∏≤‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
                    try:
                        month_el = wait.until(
                            EC.presence_of_element_located(
                                (By.XPATH, "//th[contains(text(),'256') or contains(text(),'257')]")
                            )
                        )
                        month_text = month_el.text.strip()
                        for line in month_text.split("\n"):
                            if "256" in line or "257" in line:
                                month_text = line.strip()
                                break
                    except:
                        month_text = ym
                    
                    # ‡∏î‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á (‡∏™‡∏µ‡πÅ‡∏î‡∏á = booking)
                    booked_cells = self.driver.find_elements(
                        By.XPATH,
                        "//td[contains(@class,'booking') or contains(@style,'red')]"
                    )
                    
                    booked_count = 0
                    booked_days = []
                    for cell in booked_cells:
                        day = cell.text.strip()
                        if day.isdigit():
                            booked_days.append(int(day))
                            results.append({
                                "‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå": "Deville Groups",
                                "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡πâ‡∏≤‡∏ô": house_name,
                                "‡∏£‡∏´‡∏±‡∏™": dv_code,
                                "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô": month_text,
                                "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": int(day),
                                "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞": "‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á"
                            })
                            booked_count += 1
                    
                    if booked_days:
                        days_str = ', '.join(map(str, sorted(booked_days)))
                        print(f"  üìÖ {month_text}: {booked_count} ‡∏ß‡∏±‡∏ô ‚Üí [{days_str}]")
                    else:
                        print(f"  üìÖ {month_text}: ‡∏ß‡πà‡∏≤‡∏á ‚úì")
                        
                except Exception as e:
                    print(f"  ‚õî Error ({ym}): {e}")
        
        return results


    # ========================================================
    # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 2: Pool Villa City (‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô FullCalendar + navigation)
    # ========================================================
    def scrape_poolvillacity(self, url):
        """
        Scrape ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡∏à‡∏≤‡∏Å poolvillacity.co.th
        
        ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö:
        - ‡πÉ‡∏ä‡πâ FullCalendar library
        - ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏µ‡∏•‡∏∞‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏î Next ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ)
        - ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á: ‡∏°‡∏µ fc-bg-event + background-color: rgb(248, 229, 231) + ‡∏™‡∏µ‡πÅ‡∏î‡∏á
        - ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏®‡∏Å‡∏≤‡∏•: ‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á
        - ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô data-date attribute
        """
        print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡πâ‡∏≤ Pool Villa City...")
        
        results = []
        
        # ‡∏î‡∏∂‡∏á‡∏£‡∏´‡∏±‡∏™‡∏ö‡πâ‡∏≤‡∏ô‡∏à‡∏≤‡∏Å URL (‡πÄ‡∏ä‡πà‡∏ô CITY-743)
        match = re.search(r'(CITY-\d+)', url)
        if match:
            house_code = match.group(1)
        else:
            house_code = "Unknown"
        
        self.driver.get(url)
        time.sleep(8)  # ‡∏£‡∏≠ JavaScript ‡πÇ‡∏´‡∏•‡∏î
        
        try:
            wait = WebDriverWait(self.driver, 15)
            
            # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡πâ‡∏≤‡∏ô
            try:
                title_el = wait.until(
                    EC.presence_of_element_located((By.TAG_NAME, "h1"))
                )
                house_name = title_el.text.strip()
                if not house_name:
                    house_name = house_code
            except:
                house_name = house_code
            
            print(f"  üè† ‡∏ö‡πâ‡∏≤‡∏ô: {house_name} ({house_code})")
            
            # ‡∏£‡∏≠‡πÉ‡∏´‡πâ FullCalendar ‡πÇ‡∏´‡∏•‡∏î
            try:
                wait.until(
                    EC.presence_of_element_located((By.CLASS_NAME, "fc-daygrid-day"))
                )
            except:
                print("  ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö FullCalendar - ‡∏£‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°...")
                time.sleep(5)
            
            booked_dates = set()  # ‡πÉ‡∏ä‡πâ set ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥
            
            month_map = {
                '01': '‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°', '02': '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå', '03': '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°',
                '04': '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô', '05': '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°', '06': '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô',
                '07': '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°', '08': '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°', '09': '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô',
                '10': '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°', '11': '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô', '12': '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°'
            }
            
            current_year = datetime.now().year
            current_month = datetime.now().month
            
            # ‡∏ß‡∏ô‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Next ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≠‡∏ö
            # FullCalendar ‡∏≠‡∏≤‡∏à‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏Å‡∏î Next ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á
            for round_num in range(MONTH_TO_SCRAPE):
                # ‡∏´‡∏≤ td ‡∏ó‡∏µ‡πà‡∏°‡∏µ data-date ‡πÅ‡∏•‡∏∞‡∏°‡∏µ fc-bg-event ‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏ô (‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á)
                booked_cells = self.driver.find_elements(
                    By.XPATH,
                    "//td[contains(@class,'fc-daygrid-day')]//div[contains(@class,'fc-bg-event') and contains(@style,'rgb(248, 229, 231)')]"
                )
                
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å parent td
                if not booked_cells:
                    all_day_cells = self.driver.find_elements(
                        By.XPATH,
                        "//td[contains(@class,'fc-daygrid-day') and .//div[contains(@class,'fc-bg-event')]]"
                    )
                    booked_cells = all_day_cells
                
                for cell in booked_cells:
                    try:
                        data_date = cell.get_attribute("data-date")
                        if not data_date:
                            parent_td = cell.find_element(By.XPATH, "./ancestor::td[@data-date]")
                            data_date = parent_td.get_attribute("data-date")
                        
                        if data_date:
                            booked_dates.add(data_date)
                    except:
                        pass
                
                # ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Next ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏£‡∏≠‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢)
                if round_num < MONTH_TO_SCRAPE - 1:
                    try:
                        next_btn = self.driver.find_element(
                            By.XPATH,
                            "//button[contains(@class,'fc-next-button') or contains(@aria-label,'next') or contains(@title,'Next')]"
                        )
                        next_btn.click()
                        time.sleep(2)
                    except:
                        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏∏‡πà‡∏°‡∏Å‡πá‡∏´‡∏¢‡∏∏‡∏î
                        break
            
            # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
            by_month = {}
            for date_str in sorted(booked_dates):
                parts = date_str.split('-')
                if len(parts) == 3:
                    year, month, day = parts
                    year_int = int(year)
                    month_int = int(month)
                    
                    # ‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
                    if year_int < current_year or (year_int == current_year and month_int < current_month):
                        continue
                    
                    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÅ‡∏Ñ‡πà MONTH_TO_SCRAPE ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
                    months_diff = (year_int - current_year) * 12 + (month_int - current_month)
                    if months_diff >= MONTH_TO_SCRAPE:
                        continue
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏µ ‡∏Ñ.‡∏®. ‡πÄ‡∏õ‡πá‡∏ô ‡∏û.‡∏®.
                    thai_year = int(year) + 543
                    month_name = month_map.get(month, month)
                    month_key = f"{month_name} {thai_year}"
                    
                    if month_key not in by_month:
                        by_month[month_key] = []
                    by_month[month_key].append(int(day))
                    
                    results.append({
                        "‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå": "Pool Villa City",
                        "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡πâ‡∏≤‡∏ô": house_name,
                        "‡∏£‡∏´‡∏±‡∏™": house_code,
                        "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô": month_key,
                        "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": int(day),
                        "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞": "‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á"
                    })
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
            if by_month:
                for month_key, days in sorted(by_month.items()):
                    days_str = ', '.join(map(str, sorted(days)))
                    print(f"  üìÖ {month_key}: {len(days)} ‡∏ß‡∏±‡∏ô ‚Üí [{days_str}]")
            else:
                print("  üìÖ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ß‡∏±‡∏ô‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á (‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö selector)")
                
        except Exception as e:
            print(f"  ‚õî Error: {e}")
            import traceback
            traceback.print_exc()
        
        return results


    # ========================================================
    # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 3: Pattaya Party Pool Villa (‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß + navigation)
    # ========================================================
    def scrape_pattayaparty(self, url):
        """
        Scrape ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡∏à‡∏≤‡∏Å pattayapartypoolvilla.com
        
        ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö:
        - ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ó‡∏µ‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
        - ‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏° Prev/Next ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
        - ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞: ‡πÅ‡∏î‡∏á = ‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á, ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß/‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô = ‡∏°‡∏µ‡∏à‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÇ‡∏≠‡∏ô, ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á = ‡∏ß‡∏±‡∏ô‡∏´‡∏¢‡∏∏‡∏î
        - ‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏£‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡∏≠‡∏≠‡∏Å
        """
        print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡πâ‡∏≤ Pattaya Party Pool Villa...")
        
        results = []
        
        # ‡∏î‡∏∂‡∏á‡∏£‡∏´‡∏±‡∏™‡∏ö‡πâ‡∏≤‡∏ô‡∏à‡∏≤‡∏Å URL
        match = re.search(r'/v/(\d+)', url)
        if match:
            villa_id = match.group(1)
            dv_code = f"DV-{villa_id}"
        else:
            villa_id = "Unknown"
            dv_code = "Unknown"
        
        self.driver.get(url)
        time.sleep(5)  # ‡∏£‡∏≠ JavaScript ‡πÇ‡∏´‡∏•‡∏î
        
        try:
            wait = WebDriverWait(self.driver, 15)
            
            # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡πâ‡∏≤‡∏ô‡∏à‡∏≤‡∏Å header ‡∏´‡∏£‡∏∑‡∏≠ title
            try:
                # ‡∏´‡∏≤‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å
                code_el = self.driver.find_element(By.XPATH, "//*[contains(text(),'‡∏£‡∏´‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å')]")
                house_info = code_el.text
                # ‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏≤‡∏Å title
                title = self.driver.title
                house_name = title.split('|')[0].strip() if '|' in title else title
            except:
                house_name = f"Villa {villa_id}"
            
            print(f"  üè† ‡∏ö‡πâ‡∏≤‡∏ô: {house_name} ({dv_code})")
            
            # ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "üìÖ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô
            try:
                today_btn = wait.until(
                    EC.element_to_be_clickable(
                        (By.XPATH, "//button[contains(text(),'‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ') or contains(@title,'‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô')]")
                    )
                )
                today_btn.click()
                time.sleep(2)
            except:
                pass  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏°‡∏Å‡πá‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ
            
            # ‡∏î‡∏∂‡∏á‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
            start_date = datetime.now()
            
            for i in range(MONTH_TO_SCRAPE):
                try:
                    if i > 0:
                        # ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Next ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
                        try:
                            next_btn = wait.until(
                                EC.element_to_be_clickable(
                                    (By.XPATH, "//button[contains(text(),'Next') or contains(text(),'‚ñ∫') or contains(text(),'>')]")
                                )
                            )
                            next_btn.click()
                            time.sleep(2)  # ‡∏£‡∏≠‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà
                        except Exception as e:
                            print(f"  ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Next: {e}")
                            break
                    
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏î‡∏∑‡∏≠‡∏ô/‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á
                    target_date = start_date + relativedelta(months=i)
                    expected_month = target_date.month
                    expected_year = target_date.year
                    
                    # ‡∏≠‡πà‡∏≤‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏à‡∏≤‡∏Å header ‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô
                    month_text = ""
                    try:
                        month_el = self.driver.find_element(
                            By.XPATH,
                            "//*[contains(text(),'‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°') or contains(text(),'‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå') or contains(text(),'‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°') or contains(text(),'‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô') or contains(text(),'‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°') or contains(text(),'‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô') or contains(text(),'‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°') or contains(text(),'‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°') or contains(text(),'‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô') or contains(text(),'‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°') or contains(text(),'‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô') or contains(text(),'‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°')]"
                        )
                        month_text = month_el.text.strip()
                        # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏µ
                        for line in month_text.split('\n'):
                            if any(m in line for m in ['‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°', '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå', '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°', '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô', '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°', '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô', '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°', '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°', '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô', '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°', '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô', '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°']):
                                if '256' in line or '257' in line:
                                    month_text = line.strip()
                                    break
                    except:
                        month_text = target_date.strftime("%Y-%m")
                    
                    # ‡∏´‡∏≤‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                    import calendar
                    days_in_month = calendar.monthrange(expected_year, expected_month)[1]
                    
                    # ‡∏î‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á - ‡∏´‡∏≤ div ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏µ‡πÅ‡∏î‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                    booked_days = []
                    
                    # ‡πÄ‡∏ß‡πá‡∏ö‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ div ‡πÅ‡∏ó‡∏ô table!
                    # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á = ‡∏°‡∏µ class bg-red-500 ‡πÅ‡∏•‡∏∞ text-white
                    # ‡∏ß‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏≠‡∏∑‡πà‡∏ô = ‡∏°‡∏µ class text-gray-400
                    
                    # ‡∏´‡∏≤ div ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô (‡∏°‡∏µ class grid ‡πÅ‡∏•‡∏∞ grid-cols-7)
                    # ‡∏°‡∏µ 2 ‡∏≠‡∏±‡∏ô: ‡∏≠‡∏±‡∏ô‡πÅ‡∏£‡∏Å = header (‡∏≠‡∏≤.‡∏à.‡∏≠.‡∏û.‡∏û‡∏§.‡∏®.‡∏™.), ‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á = ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ß‡∏±‡∏ô
                    try:
                        calendar_grids = self.driver.find_elements(
                            By.CSS_SELECTOR,
                            "div.grid.grid-cols-7"
                        )
                        # ‡πÉ‡∏ä‡πâ grid ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á (index 1) ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                        calendar_grid = calendar_grids[1] if len(calendar_grids) > 1 else calendar_grids[0]
                        
                        # ‡∏´‡∏≤ cell ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô
                        day_cells = calendar_grid.find_elements(
                            By.CSS_SELECTOR,
                            "div.aspect-square"
                        )
                    except:
                        # fallback - ‡∏´‡∏≤ div ‡∏ó‡∏µ‡πà‡∏°‡∏µ bg-red-500
                        day_cells = self.driver.find_elements(
                            By.CSS_SELECTOR,
                            "div.aspect-square"
                        )
                    
                    for cell in day_cells:
                        try:
                            class_attr = cell.get_attribute("class") or ""
                            cell_text = cell.text.strip()
                            
                            # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏≠‡∏∑‡πà‡∏ô (‡∏°‡∏µ text-gray-400)
                            if "text-gray-400" in class_attr or "text-gray" in class_attr:
                                continue
                            
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á (‡∏™‡∏µ‡πÅ‡∏î‡∏á: bg-red-500)
                            is_booked = "bg-red" in class_attr
                            
                            if is_booked and cell_text:
                                # ‡∏î‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏ß‡∏±‡∏ô
                                numbers = re.findall(r'\d+', cell_text)
                                if numbers:
                                    day = int(numbers[0])
                                    if 1 <= day <= days_in_month:
                                        booked_days.append(day)
                        except:
                            pass
                    
                    # ‡∏•‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ã‡πâ‡∏≥
                    booked_days = sorted(set(booked_days))
                    
                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏•‡∏á results
                    for day in booked_days:
                        results.append({
                            "‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå": "Pattaya Party Pool Villa",
                            "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡πâ‡∏≤‡∏ô": house_name,
                            "‡∏£‡∏´‡∏±‡∏™": dv_code,
                            "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô": month_text,
                            "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": day,
                            "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞": "‡∏ï‡∏¥‡∏î‡∏à‡∏≠‡∏á"
                        })
                    
                    if booked_days:
                        days_str = ', '.join(map(str, booked_days))
                        print(f"  üìÖ {month_text}: {len(booked_days)} ‡∏ß‡∏±‡∏ô ‚Üí [{days_str}]")
                    else:
                        print(f"  üìÖ {month_text}: ‡∏ß‡πà‡∏≤‡∏á ‚úì")
                        
                except Exception as e:
                    print(f"  ‚õî Error ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà {i+1}: {e}")
            
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏™‡∏î‡∏á debug info
            if not results:
                print("\n  ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏≠‡∏á - ‡∏Å‡∏≥‡∏•‡∏±‡∏á debug...")
                self._debug_calendar_structure()
                
        except Exception as e:
            print(f"  ‚õî Error: {e}")
        
        return results
    
    
    def _debug_calendar_structure(self):
        """‡πÅ‡∏™‡∏î‡∏á debug info ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô"""
        print("\n  üìã Debug: ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á HTML...")
        
        # ‡∏´‡∏≤ elements ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏è‡∏¥‡∏ó‡∏¥‡∏ô
        tables = self.driver.find_elements(By.TAG_NAME, "table")
        print(f"  - ‡∏û‡∏ö table: {len(tables)} ‡∏≠‡∏±‡∏ô")
        
        # ‡∏´‡∏≤ td ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        tds = self.driver.find_elements(By.TAG_NAME, "td")
        print(f"  - ‡∏û‡∏ö td: {len(tds)} ‡∏≠‡∏±‡∏ô")
        
        # ‡∏´‡∏≤ class ‡∏ó‡∏µ‡πà‡∏°‡∏µ bg-
        bg_elements = self.driver.find_elements(By.XPATH, "//*[contains(@class,'bg-')]")
        classes = set()
        for el in bg_elements[:50]:  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î 50 ‡∏≠‡∏±‡∏ô
            class_attr = el.get_attribute("class")
            if class_attr:
                for c in class_attr.split():
                    if 'bg-' in c:
                        classes.add(c)
        
        if classes:
            print(f"  - ‡∏û‡∏ö background classes: {list(classes)[:10]}")
        
        # Save HTML ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö debug
        try:
            with open("debug_calendar.html", "w", encoding="utf-8") as f:
                f.write(self.driver.page_source)
            print("  üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å HTML ‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà debug_calendar.html")
        except:
            pass


def main():
    print("=" * 60)
    print("üè† Pool Villa Calendar Scraper")
    print("üìÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö 3 ‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:")
    print("   1. devillegroups.com")
    print("   2. poolvillacity.co.th")
    print("   3. pattayapartypoolvilla.com")
    print("=" * 60)
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Chrome
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    
    driver = webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=options
    )
    
    scraper = CalendarScraper(driver)
    all_results = []

    # ‡πÇ‡∏´‡∏•‡∏î URL ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå webpath ‡∏´‡∏≤‡∏Å‡∏°‡∏µ ‡∏°‡∏¥‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ URLS (fallback)
    urls_from_file = load_urls_from_webpath()
    urls_to_scrape = urls_from_file if urls_from_file else URLS

    print("\nURLs ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏î‡∏∂‡∏á:")
    for i, u in enumerate(urls_to_scrape, 1):
        print(f"  {i}. {u}")

    # ‡∏ß‡∏ô scrape ‡πÅ‡∏ï‡πà‡∏•‡∏∞ URL
    for url in urls_to_scrape:
        try:
            results = scraper.scrape(url)
            all_results.extend(results)
        except Exception as e:
            print(f"‚ùå Error scraping {url}: {e}")

    driver.quit()

    # ‡∏Å‡∏£‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡∏±‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏≠‡∏≠‡∏Å
    if all_results:
        original_count = len(all_results)
        all_results = scraper.filter_past_dates(all_results)
        filtered_count = original_count - len(all_results)
        if filtered_count > 0:
            print(f"\nüóëÔ∏è ‡∏Å‡∏£‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏≠‡∏Å: {filtered_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

    # Export ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    if all_results:
        df = pd.DataFrame(all_results)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å CSV
        df.to_csv("booking_result.csv", index=False, encoding="utf-8-sig")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Excel ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
        try:
            # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ xlsxwriter ‡∏Å‡πà‡∏≠‡∏ô ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≠‡∏¢‡πÉ‡∏ä‡πâ openpyxl
            try:
                import xlsxwriter
                engine = "xlsxwriter"
            except ImportError:
                try:
                    import openpyxl
                    engine = "openpyxl"
                except ImportError:
                    engine = None
                    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö openpyxl/xlsxwriter - ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Excel")
            
            if engine:
                xlsx_file = "booking_result.xlsx"
                with pd.ExcelWriter(xlsx_file, engine=engine) as writer:
                    sheet_name = "Bookings"
                    df.to_excel(writer, index=False, sheet_name=sheet_name)
                    
                    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
                    try:
                        worksheet = writer.sheets[sheet_name]
                        
                        # Freeze ‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á
                        if engine == "xlsxwriter":
                            worksheet.freeze_panes(1, 0)
                        else:  # openpyxl
                            worksheet.freeze_panes = "A2"
                        
                        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                        col_widths = {
                            "‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå": 22,
                            "‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡πâ‡∏≤‡∏ô": 30,
                            "‡∏£‡∏´‡∏±‡∏™": 14,
                            "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô": 18,
                            "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà": 10,
                            "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞": 12,
                        }
                        
                        for idx, col in enumerate(df.columns):
                            width = col_widths.get(col, max(10, min(40, len(col) + 2)))
                            if engine == "xlsxwriter":
                                worksheet.set_column(idx, idx, width)
                            else:
                                from openpyxl.utils import get_column_letter
                                worksheet.column_dimensions[get_column_letter(idx + 1)].width = width
                        
                        # AutoFilter
                        if engine == "xlsxwriter":
                            worksheet.autofilter(0, 0, len(df), len(df.columns) - 1)
                        else:
                            from openpyxl.utils import get_column_letter
                            last_col = get_column_letter(len(df.columns))
                            last_row = len(df) + 1
                            worksheet.auto_filter.ref = f"A1:{last_col}{last_row}"
                    except Exception as e:
                        print(f"‚ö†Ô∏è ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Excel ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
                
                print(f"\n{'='*60}")
                print(f"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
                print(f"üìä ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(all_results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á)")
                print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå:")
                print(f"   üìÑ booking_result.csv")
                print(f"   üìä booking_result.xlsx")
                print(f"{'='*60}")
            else:
                print(f"\n{'='*60}")
                print(f"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
                print(f"üìä ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(all_results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á)")
                print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå: booking_result.csv")
                print(f"{'='*60}")
        except Exception as e:
            print(f"‚ö†Ô∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á Excel ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
            print(f"\n{'='*60}")
            print(f"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
            print(f"üìä ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(all_results)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏£‡∏≠‡∏á)")
            print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå: booking_result.csv")
            print(f"{'='*60}")
        
        print(df.head(20))
    else:
        print(f"\n{'='*60}")
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏≠‡∏á")
        print("üí° ‡∏≠‡∏≤‡∏à‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö CSS selector ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á HTML ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö")
        print(f"{'='*60}")


if __name__ == "__main__":
    main()
